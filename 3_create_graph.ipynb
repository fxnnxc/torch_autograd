{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch High-order Derivates with create_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=-2.0,         f = -16.0\n",
      "x=-2.0,     df/dx = 24.0\n",
      "x=-2.0, d^2f/dx^2 = -24.0\n",
      "x=-2.0, d^3f/dx^3 = 12.0\n",
      "x=-2.0, d^4f/dx^4 = 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "v = -2.0\n",
    "x = torch.tensor(v, requires_grad=True)\n",
    "\n",
    "# function \n",
    "f = 2 * x**3\n",
    "print(f\"x={v},         f = {f}\")\n",
    "\n",
    "# first order\n",
    "f.backward(retain_graph=True)\n",
    "print(f\"x={v},     df/dx = {x.grad}\")\n",
    "\n",
    "# second order\n",
    "x.grad.zero_()\n",
    "df = torch.autograd.grad(f, x, create_graph=True)[0]\n",
    "df.backward(gradient=torch.tensor(1.0))\n",
    "print(f\"x={v}, d^2f/dx^2 = {x.grad}\")\n",
    "\n",
    "# thrid order\n",
    "x.grad.zero_()\n",
    "df = torch.autograd.grad(f, x, create_graph=True)[0]\n",
    "ddf = torch.autograd.grad(df, x, create_graph=True)[0]\n",
    "ddf.backward(gradient=torch.tensor(1.0))\n",
    "print(f\"x={v}, d^3f/dx^3 = {x.grad}\")\n",
    "\n",
    "# fourth order\n",
    "x.grad.zero_()\n",
    "df = torch.autograd.grad(f, x, create_graph=True)[0]\n",
    "ddf = torch.autograd.grad(df, x, create_graph=True)[0]\n",
    "dddf = torch.autograd.grad(ddf, x, create_graph=True)[0]\n",
    "dddf.backward(gradient=torch.tensor(1.0))\n",
    "print(f\"x={v}, d^4f/dx^4 = {x.grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the result with the following equations\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\text{(function)~~~} &f = 2x^3 & \\text{when~} x=-2 \\Rightarrow 2 \\cdot (-8) = -16 \\\\\n",
    "    \\text{(first-order)~~~} &\\frac{df}{dx} = 6x^2 &  \\text{when~} x=-2 \\Rightarrow 6 \\cdot 4 = 24 \\\\\n",
    "    \\text{(second-order)~~~} &\\frac{d}{dx}\\Big(\\frac{df}{dx}\\Big) = 12x & \\text{when~} x=-2 \\Rightarrow 12 \\cdot 2 =24 \\\\\n",
    "    \\text{(third-order)~~~} &\\frac{d}{dx}\\Big(\\frac{d^2f}{dx^2}\\Big) = 12 &  \\text{when~} x=-2 \\Rightarrow 12 = 12 \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Linear(2,5)\n",
    "        self.out = nn.Linear(5, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x**2)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.out(x)\n",
    "        return x \n",
    "    \n",
    "net = Net()\n",
    "input= torch.tensor([1.0]*2, requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0906, -0.0671])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = net(input)\n",
    "f.backward()\n",
    "input.grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0906,  0.0000])\n",
      "tensor([-0.0906, -0.0671])\n"
     ]
    }
   ],
   "source": [
    "input.grad.zero_() \n",
    "f = net(input)\n",
    "gx = torch.autograd.grad(f, input, create_graph=True)[0]\n",
    "for i in range(2):\n",
    "    gx[i].backward(retain_graph=True)\n",
    "    print(input.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2138, -0.2138],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.3319,  0.3319]], grad_fn=<TBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0688, -1.0688],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 1.6595,  1.6595]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.grad.zero_() \n",
    "f = net(input)\n",
    "gx = torch.autograd.grad(f, net.mlp.weight, create_graph=True)[0]\n",
    "print(gx)\n",
    "(gx**2).sum().backward()\n",
    "net.mlp.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "728ed223cfa85ea1ef5dcc6c79a939ffd9902707d91f95b40f547e46903ca84f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
